<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 3.0.0">
  <meta name="generator" content="Hugo 0.50" />
  <meta name="author" content="Joseph D. Daws Jr.">

  
  
  
  
    
  
  <meta name="description" content="Polynomial approximation can inform network design The following is a breif discussion of work found in this preprint which has been submitted to NeurIPS 2019. In this post I&rsquo;ve left out many details. If you are interested in these details please see the preprint. As described in my previous post Neural networks have emerged as a very powerful tool for constructing nonlinear functions in high-dimensions. They are known to be very expressive in the sense that the class of functions they can approximate is very wide.">

  
  <link rel="alternate" hreflang="en-us" href="https://joedaws.github.io/post/binary-tree-network/">

  


  

  

  

  
  
  
  <meta name="theme-color" content="#ff8200">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css" integrity="sha384-5sAR7xN1Nv6T6+dT2mhtzEpVJvfS3NScPQTrOxhwjIuvcA67KV2R5Jz6kr4abQsz" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous">
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono">
  

  <link rel="stylesheet" href="/styles.css">
  

  
  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-129072488-1', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  
  

  
  <link rel="alternate" href="https://joedaws.github.io/index.xml" type="application/rss+xml" title="Joseph Daws">
  <link rel="feed" href="https://joedaws.github.io/index.xml" type="application/rss+xml" title="Joseph Daws">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://joedaws.github.io/post/binary-tree-network/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@JoeDawsJr">
  <meta property="twitter:creator" content="@JoeDawsJr">
  
  <meta property="og:site_name" content="Joseph Daws">
  <meta property="og:url" content="https://joedaws.github.io/post/binary-tree-network/">
  <meta property="og:title" content="Polynomial Inspired Neural Network Design and Initiailzation | Joseph Daws">
  <meta property="og:description" content="Polynomial approximation can inform network design The following is a breif discussion of work found in this preprint which has been submitted to NeurIPS 2019. In this post I&rsquo;ve left out many details. If you are interested in these details please see the preprint. As described in my previous post Neural networks have emerged as a very powerful tool for constructing nonlinear functions in high-dimensions. They are known to be very expressive in the sense that the class of functions they can approximate is very wide.">
  
  
    
  <meta property="og:image" content="https://joedaws.github.io/img/peak_logo.png">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2019-05-14T11:36:57-05:00">
  
  <meta property="article:modified_time" content="2019-05-14T11:36:57-05:00">
  

  

  

  <title>Polynomial Inspired Neural Network Design and Initiailzation | Joseph Daws</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >

<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Joseph Daws</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#publications">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/files/daws_cv_6_19.pdf">
            
            <span>CV</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        

      

        

        
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1 itemprop="name">Polynomial Inspired Neural Network Design and Initiailzation</h1>

  

  
    

<div class="article-metadata">

  
  
  
  <div>
    <span itemscope itemprop="author" itemtype="http://schema.org/Person">
      <span itemprop="name">Joseph Daws</span>
    </span>
    
  </div>
  

  <span class="article-date">
    
    <meta content="2019-05-14 11:36:57 -0500 -0500" itemprop="datePublished">
    <time datetime="2019-05-14 11:36:57 -0500 -0500" itemprop="dateModified">
      May 14, 2019
    </time>
  </span>
  <span itemscope itemprop="publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Joseph D. Daws Jr.">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    4 min read
  </span>
  

  
  

  
  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder"></i>
    
    <a href="/categories/neural-networks/">Neural-Networks</a>
    
  </span>
  
  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Polynomial%20Inspired%20Neural%20Network%20Design%20and%20Initiailzation&amp;url=https%3a%2f%2fjoedaws.github.io%2fpost%2fbinary-tree-network%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fjoedaws.github.io%2fpost%2fbinary-tree-network%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-facebook-f"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fjoedaws.github.io%2fpost%2fbinary-tree-network%2f&amp;title=Polynomial%20Inspired%20Neural%20Network%20Design%20and%20Initiailzation"
         target="_blank" rel="noopener">
        <i class="fab fa-linkedin-in"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fjoedaws.github.io%2fpost%2fbinary-tree-network%2f&amp;title=Polynomial%20Inspired%20Neural%20Network%20Design%20and%20Initiailzation"
         target="_blank" rel="noopener">
        <i class="fab fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Polynomial%20Inspired%20Neural%20Network%20Design%20and%20Initiailzation&amp;body=https%3a%2f%2fjoedaws.github.io%2fpost%2fbinary-tree-network%2f">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>

  
</div>



  <div class="article-container">

    <div class="article-style" itemprop="articleBody">
      

<h1 id="polynomial-approximation-can-inform-network-design">Polynomial approximation can inform network design</h1>

<p>The following is a breif discussion of work found in this <a href="https://arxiv.org/abs/1905.10457" target="_blank">preprint</a>
which has been submitted to NeurIPS 2019. In this post I&rsquo;ve left out
many details. If you are interested in these details please see the
preprint. As described in my previous
<a href="https://joedaws.github.io/post/designing-neural-networks/" title="Neural Network Design" target="_blank">post</a>
Neural networks have emerged as a very powerful tool for constructing
nonlinear functions in high-dimensions. They are known to be very expressive
in the sense that the class of functions they can approximate is very wide.
However, in order to cosntruct an approximation of a given function
a very large number of network parameters must be determined.
This is espcially true for Deep Neural Networks (DNNs).
Because DNNs have many parameters and because the functions
assocaited with solving tasks like image classification
many be quite complicated, training can be very difficult.
Although many aspects of neural network are new (such as fast training algorithms
implementable on a GPU) their expressive power and ability to appoximate
has been known for decades. However, there do not seem to be
many works which make explicit connections between the powerful
results of classical approximation theory to expressibility results for
neural networks. Below is an outline of one way in which polynomial approximation
may inform efficient approximation of complicated functions by networks.
The primary connection between these kinds of approximation is made by
by constructing a network which can approximate a given polynomial.
One can then take advantage of existing polynomial approximate results
by first finding a suitable polynomial approximation then constructing a network
which achieves this approximation. After it has been initialzed to behave
like a polynomial, the network can be trained. Our numerical examples show that
networks initialized by our proposed method have
better performance than the polynomial used to initialize them.</p>

<h2 id="a-network-for-approximating-polynomials">A Network for Approximating Polynomials</h2>

<p>Polynomials are natural objects of interest in many different areas of mathematics.
A generic degree $n$ polynomial $P_n$ is often written
$$ P_n(x) = a_0 + a_1 x + a_2 x^2 + \cdots + a_n x^n. $$
Written in this way the polynomial $P_n$ is completely characterized
by its coefficients $a_i$ for $i=0,&hellip;,n$.
Therefore, finding a suitable polynomial approximation is equivalent to
identifying coefficients. Instead of writing the polynomial
as a sum of the powers of the input $x$ one may also write a
polynomial as the product of linear shifts of the input.
According to the <strong>Fundamental Theorem of Algebra</strong>
every degree $n$ polynomial can be written
$$P_n(x) = a\Pi_{i=1}^n (x - r_i)$$
for $n$ complex numbers $r_i$ and where $a$ is a scaling factor.
We construct a network which approximates $d$-dimensional
generalizations of polynomials like $P$ by approximating the product
of $n$ numbers with a network. Such a network can be constructed
by simplying chaining together several instances of a network
which approximates the product of two numbers.
Noticing that for two real numbers $a$ and $b$
$$ 2ab = (a+b)^2 -a^2 - b^2$$, we can approximate a product by
a linear combination of the outputs of three networks. One
which approximtes $(a+b)^2$, one which approximates $a^2$ and
one which approximates $b^2$. A network which approximtaes the mapping
$x \mapsto x^2$ can be constructed from an $L$ layer network
with $4$ nodes per level.</p>

<p><img src="x2_net_new.png" alt="Network for x2" width="200"/></p>

<p>Chaining several of these networks together we can approximate
the product of $n$ numbers and hence a polynomial. The following is
a rough outline the structure of network which approximates a polynomial.</p>

<p><img src="polynomial_network.png" alt="Polynomial network" width="400"/></p>

<h2 id="initialization-based-on-polynomials">Initialization based on polynomials</h2>

<p>It is possible to initialize a network to have polynomial behavior.
Below, we have initiailzed network to a degree 6 Legendre interpolant
of a rational function.</p>

<p><img src="rational_poly_poly_init_net.png" alt="Polynomial Initialized network" width="400"/></p>

<p>This network can then be trained to achieve a good approximation of the target
rational polynomial.</p>

<p><img src="rational_poly_trained_net.png" alt="Trained Network" width="400"/></p>

<p>There are some recovery artifacts around the edges of the rational function.
We believe these are due to the fact that we did not allow
connections to form between the interior nodes of subnetworks which
approximate $x^2$. We can alieve these effects by using a simple
polynomial $x^2$ to initialize a network.</p>

<p><img src="cos_1d_deep_net_both_trained_net_3.png" alt="Realistic architecture network" width="400"/></p>

<p>Above we compare the result of trianing the same network initialized by our method to
the popular Xavier random initiailzation. We see that our network was better able to
approximate the target, at least for this example.</p>

<p>In the future, we plan to explore using this initialization scheme in real-world
problems of interest such as classificaiton.</p>

    </div>

    


<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/neural-networks/">neural-networks</a>
  
  <a class="badge badge-light" href="/tags/network-architecture/">network-architecture</a>
  
  <a class="badge badge-light" href="/tags/machine-learning/">machine-learning</a>
  
</div>



    



  







    
    
    <div class="article-widget">
      <div class="hr-light"></div>
      <h3>Related</h3>
      <ul>
        
        <li><a href="/post/designing-neural-networks/">Designing Neural Networks</a></li>
        
        <li><a href="/talk/at16-vanderbilt/">A Deep Neural Network Architecture Inspired by Polynomial Approximation</a></li>
        
      </ul>
    </div>
    

    

    


  </div>
</article>

<div class="container">
  <footer class="site-footer">
  

  <p class="powered-by">
    &copy; 2018 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    
    
    <script src="/js/mathjax-config.500a6cbb2c0f345fcecc21b3116d6637aa78f1f11db8081ea581abe05390c2e8f3bbffe61be3cf0217baf785c40efceabe51050a4f007e69af94efd3643260e8.js" integrity="sha512-UApsuywPNF/OzCGzEW1mN6p48fEduAgepYGr4FOQwujzu//mG&#43;PPAhe694XEDvzqvlEFCk8AfmmvlO/TZDJg6A=="></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    <script src="/js/hugo-academic.js"></script>
    

    
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "Search Results",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    <script src="/js/search.js"></script>
    

    
    

  </body>
</html>

