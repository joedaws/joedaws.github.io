<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>neural-networks on Joseph Daws</title>
    <link>https://joedaws.github.io/tags/neural-networks/</link>
    <description>Recent content in neural-networks on Joseph Daws</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Mon, 13 May 2019 16:40:32 -0400</lastBuildDate>
    
	<atom:link href="https://joedaws.github.io/tags/neural-networks/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>A Deep Neural Network Architecture Inspired by Polynomial Approximation</title>
      <link>https://joedaws.github.io/talk/at16-vanderbilt/</link>
      <pubDate>Mon, 13 May 2019 16:40:32 -0400</pubDate>
      
      <guid>https://joedaws.github.io/talk/at16-vanderbilt/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Polynomials, Binary Trees and Gradient Descent</title>
      <link>https://joedaws.github.io/post/binary-tree-network/</link>
      <pubDate>Mon, 14 Jan 2019 11:36:57 -0500</pubDate>
      
      <guid>https://joedaws.github.io/post/binary-tree-network/</guid>
      <description>Nonlinear Approximation As described in my previous post Neural networks have emerged as a very powerful tool for constructing nonlinear functions in high-dimensions. They are known to be very expressive in the sense that the class of functions they can approximate is very wide. However, in order to cosntruct an approximation of a given function a very large number of network parameters must be determined. This is espcially true for Deep Neural Networks (DNNs).</description>
    </item>
    
    <item>
      <title>Designing Neural Networks</title>
      <link>https://joedaws.github.io/post/designing-neural-networks/</link>
      <pubDate>Wed, 07 Nov 2018 15:23:38 -0500</pubDate>
      
      <guid>https://joedaws.github.io/post/designing-neural-networks/</guid>
      <description>Towards a mathematical understanding of using neural networks for function approximation.  An artificial neural network (ANN) is a computational framework inspired by the interactions of neurons in the brain.
 Recently many difficult problems have been effectively solved using algorithms and mathematical models which iteratively improve their performance based on data rather than explicitly finding a solution. Such methods, which primarily rely on data rather than explicit solution techniques, can be grouped together under the umbrella of Machine Learning.</description>
    </item>
    
  </channel>
</rss>