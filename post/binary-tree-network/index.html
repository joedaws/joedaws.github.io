<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 3.0.0">
  <meta name="generator" content="Hugo 0.50" />
  <meta name="author" content="Joseph D. Daws Jr.">

  
  
  
  
    
  
  <meta name="description" content="Nonlinear Approximation As described in my previous post Neural networks have emerged as a very powerful tool for constructing nonlinear functions in high-dimensions. They are known to be very expressive in the sense that the class of functions they can approximate is very wide. However, in order to cosntruct an approximation of a given function a very large number of network parameters must be determined. This is espcially true for Deep Neural Networks (DNNs).">

  
  <link rel="alternate" hreflang="en-us" href="https://joedaws.github.io/post/binary-tree-network/">

  


  

  

  

  
  
  
  <meta name="theme-color" content="#ff8200">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css" integrity="sha384-5sAR7xN1Nv6T6+dT2mhtzEpVJvfS3NScPQTrOxhwjIuvcA67KV2R5Jz6kr4abQsz" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous">
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono">
  

  <link rel="stylesheet" href="/styles.css">
  

  
  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-129072488-1', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  
  

  
  <link rel="alternate" href="https://joedaws.github.io/index.xml" type="application/rss+xml" title="Joseph Daws">
  <link rel="feed" href="https://joedaws.github.io/index.xml" type="application/rss+xml" title="Joseph Daws">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://joedaws.github.io/post/binary-tree-network/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@JoeDawsJr">
  <meta property="twitter:creator" content="@JoeDawsJr">
  
  <meta property="og:site_name" content="Joseph Daws">
  <meta property="og:url" content="https://joedaws.github.io/post/binary-tree-network/">
  <meta property="og:title" content="Polynomials, Binary Trees and Gradient Descent | Joseph Daws">
  <meta property="og:description" content="Nonlinear Approximation As described in my previous post Neural networks have emerged as a very powerful tool for constructing nonlinear functions in high-dimensions. They are known to be very expressive in the sense that the class of functions they can approximate is very wide. However, in order to cosntruct an approximation of a given function a very large number of network parameters must be determined. This is espcially true for Deep Neural Networks (DNNs).">
  
  
    
  <meta property="og:image" content="https://joedaws.github.io/img/joe_pic_grad.JPG">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2019-01-14T11:36:57-05:00">
  
  <meta property="article:modified_time" content="2019-01-14T11:36:57-05:00">
  

  

  

  <title>Polynomials, Binary Trees and Gradient Descent | Joseph Daws</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >

<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Joseph Daws</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#publications">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        

      

        

        
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1 itemprop="name">Polynomials, Binary Trees and Gradient Descent</h1>

  

  
    

<div class="article-metadata">

  
  
  
  <div>
    <span itemscope itemprop="author" itemtype="http://schema.org/Person">
      <span itemprop="name">Joseph Daws</span>
    </span>
    
  </div>
  

  <span class="article-date">
    
    <meta content="2019-01-14 11:36:57 -0500 EST" itemprop="datePublished">
    <time datetime="2019-01-14 11:36:57 -0500 EST" itemprop="dateModified">
      Jan 14, 2019
    </time>
  </span>
  <span itemscope itemprop="publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Joseph D. Daws Jr.">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    3 min read
  </span>
  

  
  

  
  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder"></i>
    
    <a href="/categories/neural-networks/">Neural-Networks</a>
    
  </span>
  
  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Polynomials%2c%20Binary%20Trees%20and%20Gradient%20Descent&amp;url=https%3a%2f%2fjoedaws.github.io%2fpost%2fbinary-tree-network%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fjoedaws.github.io%2fpost%2fbinary-tree-network%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-facebook-f"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fjoedaws.github.io%2fpost%2fbinary-tree-network%2f&amp;title=Polynomials%2c%20Binary%20Trees%20and%20Gradient%20Descent"
         target="_blank" rel="noopener">
        <i class="fab fa-linkedin-in"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fjoedaws.github.io%2fpost%2fbinary-tree-network%2f&amp;title=Polynomials%2c%20Binary%20Trees%20and%20Gradient%20Descent"
         target="_blank" rel="noopener">
        <i class="fab fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Polynomials%2c%20Binary%20Trees%20and%20Gradient%20Descent&amp;body=https%3a%2f%2fjoedaws.github.io%2fpost%2fbinary-tree-network%2f">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>

  
</div>



  <div class="article-container">

    <div class="article-style" itemprop="articleBody">
      

<h1 id="nonlinear-approximation">Nonlinear Approximation</h1>

<p>As described in my previous <a href="https://joedaws.github.io/post/designing-neural-networks/" title="Neural Network Design" target="_blank">post</a>
Neural networks have emerged as a very powerful tool for constructing
nonlinear functions in high-dimensions. They are known to be very expressive
in the sense that the class of functions they can approximate is very wide.
However, in order to cosntruct an approximation of a given function
a very large number of network parameters must be determined.
This is espcially true for Deep Neural Networks (DNNs).
Because DNNs have many parameters and because the functions
assocaited with solving tasks like image classification
many be quite complicated, training can be very difficult.
Although many aspects of neural network are new (such as fast training algorithms
implementable on a GPU) their expressive power and ability to appoximate
has been considered for a long time, but I personally haven&rsquo;t seen
many works which make explicit connections between the powerful
results of classical approximation theory to expressibility results for
neural networks. Below is an outline of one way in which polynomial approximation
may be able to help networks approximate difficult function. By constructing
a network which can approximate a polynomial we can take advantage of
existing polynomial approximate results. On the other hand since
networks are so expressive, given a polynoial approximation,
we can generate a network which is first initialized to take on the behavior of
the polynomial, then trained to find an even better approximation.</p>

<h2 id="polynomial-approximation">Polynomial Approximation</h2>

<p>Polynomials are natural objects of interest in many different areas of mathematics.
A generic degree $n$ polynomial $P_n$ is often written
$$ P_n(x) = a_0 + a_1 x + a_2 x^2 + \cdots + a_n x^n. $$
Written in this way the polynomial $P_n$ is completely characterized
by its coefficients $a_i$ for $i=0,&hellip;,n$.
Therefore, finding a suitable polynomial approximation is equivalent to
identifying the correct coefficients.</p>

<p>According to the fundamental theorem of algebra
Suppose that you know a root of the polynomial $P$ is $r$. Then
it is possible to write
$P(x) = (x-r)Q(x)$ in light of our observation about numbers and
since $x-r = 0$ when $x=r$ for some other polynomials $Q$.
Iterating this process we can write polynonials as
a product of $n$ numbers of the form $(x-r_i)$ for $i=1,\dots,n$.
This fact is known as the <strong>Fundamental Theorem of Algebra</strong>.
It is known that every degree $n$ polynomial can be written
$$ P_n(x) = \Pi_{i=1}^n (x - r_i) $$
for $n$ complex numbers $r_i$.
We now how two representations of $P_n(x)$i. One written
entirely as a linear combination of the powers of $x$ and the other
as products of affine functions $(x-r_i)$.
Each representation is equally valid and has its own usefulness.
There may also be other interesting representations of polynomials
which involve not only products and linear combinations but also
compositions of polynomials.</p>

    </div>

    


<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/neural-networks/">neural-networks</a>
  
  <a class="badge badge-light" href="/tags/network-architecture/">network-architecture</a>
  
  <a class="badge badge-light" href="/tags/machine-learning/">machine-learning</a>
  
</div>



    



  







    
    
    <div class="article-widget">
      <div class="hr-light"></div>
      <h3>Related</h3>
      <ul>
        
        <li><a href="/post/designing-neural-networks/">Designing Neural Networks</a></li>
        
      </ul>
    </div>
    

    

    


  </div>
</article>

<div class="container">
  <footer class="site-footer">
  

  <p class="powered-by">
    &copy; 2018 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    
    
    <script src="/js/mathjax-config.500a6cbb2c0f345fcecc21b3116d6637aa78f1f11db8081ea581abe05390c2e8f3bbffe61be3cf0217baf785c40efceabe51050a4f007e69af94efd3643260e8.js" integrity="sha512-UApsuywPNF/OzCGzEW1mN6p48fEduAgepYGr4FOQwujzu//mG&#43;PPAhe694XEDvzqvlEFCk8AfmmvlO/TZDJg6A=="></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    <script src="/js/hugo-academic.js"></script>
    

    
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "Search Results",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    <script src="/js/search.js"></script>
    

    
    

  </body>
</html>

